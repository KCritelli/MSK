{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "lis_ = defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = \"nlp_text.txt\"\n",
    "outfile = \"cleaned_file.txt\"\n",
    "\n",
    "delete_list = [\"=\"]\n",
    "fin = open(infile)\n",
    "fout = open(outfile, \"w+\")\n",
    "for line in fin:\n",
    "    for word in delete_list:\n",
    "        line = line.replace(word, \"\")\n",
    "    fout.write(line)\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cleaned_file.txt\", \"rt\") as fin:\n",
    "    with open(\"nlp2.txt\", \"wt\") as fout:\n",
    "        for line in fin:\n",
    "            fout.write(line.replace('||', '='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "cancer_text = pd.read_excel('cancerText.xlsx', sheetname='Sheet2')\n",
    "\n",
    "cancer_text.columns = ['ID','Text']\n",
    "cancer_data = pd.read_csv('train_aa_extra.csv')\n",
    "cancer_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "frames = [cancer_data, cancer_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerTotal = pd.merge(cancer_data, cancer_text, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = cancerTotal[cancerTotal['Class'] == 1]\n",
    "class2 = cancerTotal[cancerTotal['Class'] == 2]\n",
    "class2_subset = class2[class2.Text.duplicated() == False]\n",
    "class1_subset = class1[class1.Text.duplicated() == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')\n",
    "tf_class2 = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294529"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix =  tf.fit_transform(class1_subset.Text)\n",
    "tfidf_matrix2 = tf_class2.fit_transform(class2_subset.Text)\n",
    "feature_names = tf.get_feature_names() \n",
    "feature_names2 = tf_class2.get_feature_names()\n",
    "len(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294529"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix\n",
    "tfidf_matrix2\n",
    "dense = tfidf_matrix.todense()\n",
    "dense2 = tfidf_matrix2.todense()\n",
    "len(dense[0].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_words = dense[0].tolist()[0]\n",
    "class_words2 = dense2[0].tolist()[0]\n",
    "phrase_scores = [pair for pair in zip(range(0, len(class_words)), class_words) if pair[1] > 0]\n",
    "phrase_scores2 = [pair for pair in zip(range(0, len(class_words2)), class_words2) if pair[1] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbl                  0.681035781489112\n",
      "loh                  0.11330215180338506\n",
      "cbl mutations        0.09367960594390486\n",
      "h94y                 0.09367960594390486\n",
      "s80n                 0.09367960594390486\n",
      "s80n h94y            0.09367960594390486\n",
      "taiwanese            0.09093943725377807\n",
      "q249e                0.08698820551934024\n",
      "w802                 0.08698820551934024\n",
      "egfr                 0.08064303109027307\n",
      "lung                 0.07502802746146157\n",
      "met egfr             0.07494590933659642\n",
      "ring finger          0.07388829276869469\n",
      "african              0.06579849261914447\n",
      "met                  0.0652875285784702\n",
      "mutations            0.06198582764456129\n",
      "h94y q249e           0.0602226038210817\n",
      "q249e w802           0.0602226038210817\n",
      "s80n h94y q249e      0.0602226038210817\n",
      "tkb                  0.05620943200244731\n",
      "finger               0.05557519515547279\n",
      "cbl mutants          0.05353120339651707\n",
      "cbl mutation         0.05353120339651707\n",
      "h94y q249e w802      0.05353120339651707\n",
      "cell                 0.050847123442554605\n",
      "p____0               0.05037299738413774\n",
      "lung cancer          0.0501294517588184\n",
      "ring finger domain   0.049963939557730944\n",
      "mutation             0.04947943351459716\n",
      "ring                 0.04875676568136161\n"
     ]
    }
   ],
   "source": [
    "sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "sorted_phrase_scores2 = sorted(phrase_scores2, key = lambda t: t[1] * -1)\n",
    "#for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:30]:\n",
    "#   print('{0: <20} {1}'.format(phrase, score))\n",
    "for phrase, score in [(feature_names2[word_id], score) for (word_id, score) in sorted_phrase_scores2][:30]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(271523, 0.6652867899292048),\n",
       " (473721, 0.2872293230762133),\n",
       " (367239, 0.25478807860878017),\n",
       " (271543, 0.24239131105947767),\n",
       " (1141169, 0.10208322411945689)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(phrase_scores, key=lambda t: t[1] * -1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdk10                0.6652867899292048\n",
      "ets2                 0.2872293230762133\n",
      "cyclin               0.25478807860878017\n",
      "cdk10 cyclin         0.24239131105947767\n",
      "star                 0.10208322411945689\n",
      "6his                 0.08251619099897113\n",
      "star syndrome        0.07735892906153544\n",
      "fig                  0.06746923265014898\n",
      "ets2 protein         0.06704440518666405\n",
      "gst cdk10            0.06704440518666405\n",
      "myc cdk10            0.061887143249228345\n",
      "cdk10 wt             0.05672988131179266\n",
      "strepii              0.05672988131179266\n",
      "v5 6his              0.05672988131179266\n",
      "mcf7                 0.053708193263610544\n",
      "mcf7 cells           0.052801667647994946\n",
      "silencing            0.05245632914881128\n",
      "cdk10 wt kd          0.051572619374356955\n",
      "cyclin silencing     0.051572619374356955\n",
      "fam58a               0.051572619374356955\n",
      "----------------------------------------\n",
      "cbl                  0.681035781489112\n",
      "loh                  0.11330215180338506\n",
      "cbl mutations        0.09367960594390486\n",
      "h94y                 0.09367960594390486\n",
      "s80n                 0.09367960594390486\n",
      "s80n h94y            0.09367960594390486\n",
      "taiwanese            0.09093943725377807\n",
      "q249e                0.08698820551934024\n",
      "w802                 0.08698820551934024\n",
      "egfr                 0.08064303109027307\n",
      "lung                 0.07502802746146157\n",
      "met egfr             0.07494590933659642\n",
      "ring finger          0.07388829276869469\n",
      "african              0.06579849261914447\n",
      "met                  0.0652875285784702\n",
      "mutations            0.06198582764456129\n",
      "h94y q249e           0.0602226038210817\n",
      "q249e w802           0.0602226038210817\n",
      "s80n h94y q249e      0.0602226038210817\n",
      "tkb                  0.05620943200244731\n"
     ]
    }
   ],
   "source": [
    "sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))\n",
    "print('----------------------------------------')\n",
    "sorted_phrase_scores = sorted(phrase_scores2, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names2[word_id], score) for (word_id, score) in sorted_phrase_scores2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
